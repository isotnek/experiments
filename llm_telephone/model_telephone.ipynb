{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baf324bb",
   "metadata": {},
   "source": [
    "# Experimental Setup\n",
    "\n",
    "In this experiment I'll be using the [Stable Diffusion 2](https://huggingface.co/stabilityai/stable-diffusion-2) model to generate an image and the [Blip Large](https://huggingface.co/Salesforce/blip-image-captioning-large) model to caption to the images, and then using the caption as the next input prompt to Stable Diffusion. Ill then run this for N cycles, looking at the semantic decay that occurs over all and between cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc58ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "import torch\n",
    "from PIL import Image\n",
    "import transformers\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bdaf3b",
   "metadata": {},
   "source": [
    "### starting with some Transformers weirdness\n",
    "\n",
    "From the [docs](https://huggingface.co/docs/diffusers/optimization/mps): \"We recommend to “prime” the pipeline using an additional one-time pass through it. This is a temporary workaround for a weird issue we have detected: the first inference pass produces slightly different results than subsequent ones. You only need to do this pass once, and it’s ok to use just one inference step and discard the result.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f215cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055036322941479fbe805a5f19a8bba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "/Users/iansotnek/miniforge3/envs/mldev/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d914559d974948adfaf6a6ac838cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iansotnek/miniforge3/envs/mldev/lib/python3.10/site-packages/diffusers/schedulers/scheduling_euler_discrete.py:168: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1666646835428/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  step_index = (self.timesteps == timestep).nonzero().item()\n"
     ]
    }
   ],
   "source": [
    "#set up the stable diffusion pipeline\n",
    "\n",
    "diffusion_model_id = 'stabilityai/stable-diffusion-2'\n",
    "\n",
    "scheduler = EulerDiscreteScheduler.from_pretrained(diffusion_model_id, subfolder = 'scheduler')\n",
    "\n",
    "sd_pipe = StableDiffusionPipeline.from_pretrained(diffusion_model_id, scheduler = scheduler)\n",
    "\n",
    "sd_pipe.to('mps')\n",
    "\n",
    "sd_pipe.enable_attention_slicing()\n",
    "\n",
    "\n",
    "#warm-up prompt\n",
    "\n",
    "initial_prompt = 'An oil painting of a pirate ship made of Swiss cheese'\n",
    "\n",
    "_ = sd_pipe(initial_prompt, num_inference_steps = 1) \n",
    "\n",
    "#warmup_image = sd_pipe(initial_prompt).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08496951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the experiment         \n",
    "if not os.path.exists('images'):\n",
    "    os.mkdir('images')\n",
    "    \n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "    \n",
    "cycles = 10\n",
    "\n",
    "first_real_prompt = 'A brown and white corgi is eating a large watermelon while sitting on a towel at the beach'\n",
    "\n",
    "prompts = np.array([first_real_prompt])\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "captioning_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4803c081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60efba98ca1413ea2cf222e19ca1e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iansotnek/miniforge3/envs/mldev/lib/python3.10/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64356762bb21447fbe2bf393f6a4b7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dce79c0ba854e648de8f877bce8317c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017b728e1e894f59be7b87b27d3e9876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167bf93346264a7aba7afef3bb9e93e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fac7562e82450a98c886729b441102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a200ffaa35a7462287872406f0e3ed1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130c205fb917459ebce704270b2fe38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5c1c547c1149438255fbd396880252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020b02cc6a2f4501b0d04cca984ae355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(cycles):\n",
    "    prompt = prompts[i]\n",
    "    image = sd_pipe(prompt).images[0]\n",
    "    \n",
    "    image_path = f'images/image_{i}.jpeg'\n",
    "    image.save(image_path, 'JPEG')\n",
    "    \n",
    "    raw_image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    caption_inputs = processor(raw_image, return_tensors = 'pt')\n",
    "        \n",
    "    blip_out = captioning_model.generate(**caption_inputs)\n",
    "    \n",
    "    caption = processor.decode(blip_out[0], skip_special_tokens = True)\n",
    "    \n",
    "    prompts = np.append(prompts, [caption])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e25a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(prompts, columns = ['prompts'])\n",
    "data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec1e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
